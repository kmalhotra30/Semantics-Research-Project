{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from xml.dom import minidom\n",
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename = 'semcor/br-a01.xml', omit = False, vocabulary = False):\n",
    "    mydoc = minidom.parse(filename)\n",
    "    items = mydoc.getElementsByTagName('word')\n",
    "    text = []\n",
    "    sense = []\n",
    "    for elem in items:  \n",
    "        if elem.attributes['text'].value in vocabulary:\n",
    "            try:\n",
    "                if elem.attributes['sense']:\n",
    "                    text.append('[MASC]')\n",
    "                    sense.append((elem.attributes['text'].value, elem.attributes['sense'].value))\n",
    "            except Exception:\n",
    "                text.append(elem.attributes['text'].value)\n",
    "                \n",
    "    '''    if omit:\n",
    "        for elem in items: \n",
    "            if elem.attributes['text'].value in vocabulary:\n",
    "                try:\n",
    "                    if elem.attributes['sense']:\n",
    "                        text.append('[MASC]')\n",
    "                        sense[elem.attributes['text'].value] = elem.attributes['sense'].value\n",
    "                except Exception:\n",
    "                    text.append(elem.attributes['text'].value)'''\n",
    "                    \n",
    "    return (text, sense) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "directory = 'semcor/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xml\"): \n",
    "        filenames.append(os.path.join(directory, filename))\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "Vocabulary = set(tokenizer.vocab.keys())\n",
    "model = BertModel.from_pretrained('bert-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "i = 0\n",
    "for filename in filenames:\n",
    "    i+=1\n",
    "    #print(i)\n",
    "    docs.append(get_text(filename, True, Vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2167 > 512). Running this sequence through BERT will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2857,  1254,   117,  ..., 10638,   107,   119]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor(tokenizer.convert_tokens_to_ids(docs[0][0]))[None, :]\n",
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_text(text, model, num_layer, idx, window):\n",
    "    leftBound = max(0, idx-window)\n",
    "    rightBound = min(idx+window, len(text))\n",
    "    sentences = text[leftBound:rightBound]\n",
    "    #sentences.remove('[MASC]')\n",
    "    sentences = list(filter(lambda a: a != '[MASC]', sentences))\n",
    "    tokens_tensor = torch.tensor(tokenizer.convert_tokens_to_ids(sentences))[None, :]\n",
    "    with torch.no_grad():\n",
    "        encoded_layers,_  = model(tokens_tensor)\n",
    "    return encoded_layers[num_layer].mean(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_doc(doc, model, num_layer, window):\n",
    "    text = doc[0]\n",
    "    idxs = [i for i,val in enumerate(text) if val=='[MASC]']\n",
    "    embeddings = []\n",
    "    for idx in idxs:\n",
    "        embeddings.append(get_embedding_text(text = text, model = model, num_layer = num_layer, idx =  idx, window = window))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = get_embeddings_doc(docs[0], model = model, num_layer = 23, window = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings_docs = []\n",
    "for doc in docs:\n",
    "    embeddings_docs.append((doc[0], doc[1], get_embeddings_doc(doc, model = model, num_layer = 23, window = 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_docs = []\n",
    "embeddings_docs.append((doc[0], doc[1], get_embeddings_doc(doc, model = model, num_layer = 23, window = 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(embeddings_docs[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (['Once again'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e207963ef26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_embedding_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'num_layer' is not defined"
     ]
    }
   ],
   "source": [
    "get_embedding_text(text, model, num_layer, idx, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
